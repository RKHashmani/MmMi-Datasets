# HTCondor job submission for parameter sweep using indices

JobBatchName            = "MI_Sweep_mm"
universe                = container
docker_image            = docker://rkhashmani/mutual_info_flow_matching:1.0.0
# To prevent the use of cached images:
docker_pull_policy      = always

# Specify your executable (single binary or a script that runs several commands) and arguments to be passed to jobs.
# $(Process) will be a integer number for each job, starting with "0" and increasing for the relevant number of jobs.

executable              = sweep_generate.sh
arguments               = $(Process)

# To fix a matplotlib bug, we need to set the MPLCONFIGDIR and MPLBACKEND environment variables.
environment             = "MPLCONFIGDIR=/tmp/ MPLBACKEND=Agg"

# IMPORTANT! Require execute servers that can access /staging
Requirements            = (Target.HasCHTCStaging == true) && (CUDACapability >= 7.5)

should_transfer_files   = YES
when_to_transfer_output = ON_EXIT
transfer_output_files   = output_dir/datasets
transfer_output_remaps  = "output_dir/datasets = osdf:///chtc/staging/hashmani/datasets_$(Cluster)"

transfer_input_files    = \
    generation_arguments, \
    sweep_generate.py, \
    sweep_generate.sh, \
    models, \
    output_dir, \
    training, \
    dataset_generation.py, \
    dataset_generation, \

# Specify the name of the log, standard error, and standard output (or "screen output") files. Wherever you see $(Cluster), HTCondor will insert the
#  queue number assigned to this set of jobs at the time of submission.
log                     = HTCondor_logs/job_$(Cluster)_$(Process).log
error                   = HTCondor_logs/job_$(Cluster)_$(Process).err
output                  = HTCondor_logs/job_$(Cluster)_$(Process).out

request_cpus            = 1
request_disk            = 4GB
request_memory          = 32GB
request_gpus            = 1
gpus_minimum_memory     = 10240
+WantGPULab             = true
+GPUJobLength           = "short"

queue 16
# 3^7=2187 jobs for SWEEP_VALUES = [0.01,0.1,1.0]
